{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645ffd70",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "\n",
    "Data: [The Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbbcbdf4-9504-4324-9a7f-72b59a7ee125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "source_dir = './dogvscat/images'\n",
    "binary_dir = './dogvscat/binary_classification'\n",
    "multiclass_dir = './dogvscat/multiclass_classification'\n",
    "\n",
    "os.makedirs(binary_dir, exist_ok=True)\n",
    "os.makedirs(multiclass_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(os.path.join(binary_dir, 'Cat'), exist_ok=True)\n",
    "os.makedirs(os.path.join(binary_dir, 'Dog'), exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "#classify types\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        # Getting names of the breeds(without \".jpg\"\n",
    "        breed = '_'.join(filename.split('_')[:-1])  # keep\"_\"\n",
    "        source_file = os.path.join(source_dir, filename)\n",
    "\n",
    "        # Divide into Cat and Dog\n",
    "        if breed[0].isupper():  # uppercase = Cat\n",
    "            shutil.copy(source_file, os.path.join(binary_dir, 'Cat', filename))\n",
    "            # Copy to breed folder\n",
    "            breed_dir = os.path.join(multiclass_dir, breed)\n",
    "            os.makedirs(breed_dir, exist_ok=True)\n",
    "            shutil.copy(source_file, os.path.join(breed_dir, filename))\n",
    "        elif breed[0].islower():  # lowercase = Dog\n",
    "            shutil.copy(source_file, os.path.join(binary_dir, 'Dog', filename))\n",
    "            # Copy to breed folder\n",
    "            breed_dir = os.path.join(multiclass_dir, breed)\n",
    "            os.makedirs(breed_dir, exist_ok=True)\n",
    "            shutil.copy(source_file, os.path.join(breed_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f05c43-ffa4-4cc3-ae23-4f1e7ceabeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a1b1d-79b4-42d8-b062-d38105710ec5",
   "metadata": {},
   "source": [
    "### First trial with ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ffccc68-9ad7-46b2-ae4e-6b27e925c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # model mode: training\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)  # send images to GPU\n",
    "            labels = labels.to(device)  # send labels to GPU\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "def test_model():\n",
    "    model.eval()  # model mode: evaluating\n",
    "    total = correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)  # send images to GPU\n",
    "            labels = labels.to(device)  # send labels to GPU\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30351616-bf1b-4a77-97c0-e5dd6689f274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0945\n",
      "Epoch [2/10], Loss: 0.0292\n",
      "Epoch [3/10], Loss: 0.0169\n",
      "Epoch [4/10], Loss: 0.0016\n",
      "Epoch [5/10], Loss: 0.0375\n",
      "Epoch [6/10], Loss: 0.0211\n",
      "Epoch [7/10], Loss: 0.1927\n",
      "Epoch [8/10], Loss: 0.0171\n",
      "Epoch [9/10], Loss: 0.0010\n",
      "Epoch [10/10], Loss: 0.1240\n",
      "Test Accuracy: 90.26%\n"
     ]
    }
   ],
   "source": [
    "#1.binary classification problem\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "## If MacOS, use this ðŸ‘‡ device selector instead\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "weights = models.ResNet18_Weights.DEFAULT\n",
    "model = models.resnet18(weights=weights).to(device)\n",
    "\n",
    "\n",
    "# data transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# dataset path\n",
    "dataset_path = './oxford-iiit-pet/images/images//binary_classification'\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = int(0.2 * total_size)\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2).to(device)  # Adjusting the final layer for binary classification\n",
    "\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, criterion, optimizer)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a551f-45c0-4ac0-8a56-047fcf8046be",
   "metadata": {},
   "source": [
    "### Adjustment for binary task:  \n",
    "Epochs - 20  \n",
    "Learning rate - 0.00005  \n",
    "Added settings to image transformer - RandomCrop (instead of CenterCrop), RandomHorizontalFlip(), RandomRotation(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8643b837-eb07-412d-b82a-4a5018d956aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.1099\n",
      "Epoch [2/20], Loss: 0.0080\n",
      "Epoch [3/20], Loss: 0.0009\n",
      "Epoch [4/20], Loss: 0.0319\n",
      "Epoch [5/20], Loss: 0.0004\n",
      "Epoch [6/20], Loss: 0.1547\n",
      "Epoch [7/20], Loss: 0.0020\n",
      "Epoch [8/20], Loss: 0.0005\n",
      "Epoch [9/20], Loss: 0.0005\n",
      "Epoch [10/20], Loss: 0.0006\n",
      "Epoch [11/20], Loss: 0.0171\n",
      "Epoch [12/20], Loss: 0.0296\n",
      "Epoch [13/20], Loss: 0.0061\n",
      "Epoch [14/20], Loss: 0.0030\n",
      "Epoch [15/20], Loss: 0.0005\n",
      "Epoch [16/20], Loss: 0.0006\n",
      "Epoch [17/20], Loss: 0.0004\n",
      "Epoch [18/20], Loss: 0.0003\n",
      "Epoch [19/20], Loss: 0.0001\n",
      "Epoch [20/20], Loss: 0.0000\n",
      "Test Accuracy: 99.32%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "weights = models.ResNet18_Weights.DEFAULT\n",
    "model = models.resnet18(weights=weights).to(device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# dataset path\n",
    "dataset_path = './oxford-iiit-pet/images/images//binary_classification'\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = int(0.2 * total_size)\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load pretrained ResNet\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2).to(device)  # Adjusting the final layer for binary classification\n",
    "\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.00005)#enhanced a lot\n",
    "num_epoch = 20\n",
    "\n",
    "# Training and Evaluation\n",
    "train_model(model, criterion, optimizer, num_epoch)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241b567f-02cc-42f1-a274-45bfe1cf8017",
   "metadata": {},
   "source": [
    "### First Trial for multi-class problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdfcb95-21ee-4f32-8bdb-bd2b7797399b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.0054\n",
      "Epoch [2/10], Loss: 0.4915\n",
      "Epoch [3/10], Loss: 0.9676\n",
      "Epoch [4/10], Loss: 0.8297\n",
      "Epoch [5/10], Loss: 0.5319\n",
      "Epoch [6/10], Loss: 0.3422\n",
      "Epoch [7/10], Loss: 0.6671\n",
      "Epoch [8/10], Loss: 0.3968\n",
      "Epoch [9/10], Loss: 0.4686\n",
      "Epoch [10/10], Loss: 0.4815\n",
      "Test Accuracy: 81.33%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "weights = models.ResNet18_Weights.DEFAULT\n",
    "model = models.resnet18(weights=weights).to(device)\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # freeze all layers first\n",
    "\n",
    "# finetune: unfreeze layer4\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# replace the fullly-connected layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 37).to(device)\n",
    "\n",
    "# data transform and data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# dataset path\n",
    "dataset_path = './dogvscat/multiclass_classification'\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = int(0.2 * total_size)\n",
    "# Split the dataset\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# setting learning rate with Adam optimizer\n",
    "optimizer = Adam([\n",
    "    {'params': model.layer4.parameters(), 'lr': 1e-4},  \n",
    "    {'params': model.fc.parameters()}  \n",
    "], lr=1e-3)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Training and Evaluation\n",
    "train_model(model, criterion, optimizer)\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57791d11-e351-4d4e-abd7-af3e900035b8",
   "metadata": {},
   "source": [
    "### Adjustment for multi-class task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be155089-08e1-4c4c-b2d3-c1702cce28ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_earlystop(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    best_accuracy = 0\n",
    "    patience = 10\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation phase\n",
    "        val_accuracy = validate_model(model, val_loader)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, '\n",
    "              f'LR: {optimizer.param_groups[0][\"lr\"]:.6f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            no_improve_epochs = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"Saved new best model\")\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "        \n",
    "        if no_improve_epochs >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "def validate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    total = correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def retrain_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in full_train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706d7627-1ce4-4b83-a246-abfa32105909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /home/akhmed/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100.0%\n",
      "/home/akhmed/miniconda3/envs/dd2424/lib/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1712608885084/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:84.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.1817, LR: 0.000100, Val Accuracy: 91.88%\n",
      "Saved new best model\n",
      "Epoch [2/50], Loss: 0.3701, LR: 0.000100, Val Accuracy: 93.50%\n",
      "Saved new best model\n",
      "Epoch [3/50], Loss: 0.1319, LR: 0.000100, Val Accuracy: 94.68%\n",
      "Saved new best model\n",
      "Epoch [4/50], Loss: 0.3188, LR: 0.000100, Val Accuracy: 93.59%\n",
      "Epoch [5/50], Loss: 0.3302, LR: 0.000010, Val Accuracy: 93.86%\n",
      "Epoch [6/50], Loss: 0.0299, LR: 0.000010, Val Accuracy: 95.22%\n",
      "Saved new best model\n",
      "Epoch [7/50], Loss: 0.0150, LR: 0.000010, Val Accuracy: 94.77%\n",
      "Epoch [8/50], Loss: 0.0759, LR: 0.000010, Val Accuracy: 94.68%\n",
      "Epoch [9/50], Loss: 0.0447, LR: 0.000010, Val Accuracy: 95.31%\n",
      "Saved new best model\n",
      "Epoch [10/50], Loss: 0.0149, LR: 0.000001, Val Accuracy: 95.22%\n",
      "Epoch [11/50], Loss: 0.0081, LR: 0.000001, Val Accuracy: 95.13%\n",
      "Epoch [12/50], Loss: 0.0052, LR: 0.000001, Val Accuracy: 95.67%\n",
      "Saved new best model\n",
      "Epoch [13/50], Loss: 0.0149, LR: 0.000001, Val Accuracy: 95.76%\n",
      "Saved new best model\n",
      "Epoch [14/50], Loss: 0.0967, LR: 0.000001, Val Accuracy: 94.95%\n",
      "Epoch [15/50], Loss: 0.0119, LR: 0.000000, Val Accuracy: 94.68%\n",
      "Epoch [16/50], Loss: 0.0217, LR: 0.000000, Val Accuracy: 95.58%\n",
      "Epoch [17/50], Loss: 0.0032, LR: 0.000000, Val Accuracy: 96.30%\n",
      "Saved new best model\n",
      "Epoch [18/50], Loss: 0.0708, LR: 0.000000, Val Accuracy: 95.22%\n",
      "Epoch [19/50], Loss: 0.0565, LR: 0.000000, Val Accuracy: 94.95%\n",
      "Epoch [20/50], Loss: 0.1227, LR: 0.000000, Val Accuracy: 95.85%\n",
      "Epoch [21/50], Loss: 0.0297, LR: 0.000000, Val Accuracy: 95.31%\n",
      "Epoch [22/50], Loss: 0.0186, LR: 0.000000, Val Accuracy: 95.49%\n",
      "Epoch [23/50], Loss: 0.0124, LR: 0.000000, Val Accuracy: 95.67%\n",
      "Epoch [24/50], Loss: 0.0406, LR: 0.000000, Val Accuracy: 95.31%\n",
      "Epoch [25/50], Loss: 0.0209, LR: 0.000000, Val Accuracy: 95.31%\n",
      "Epoch [26/50], Loss: 0.0372, LR: 0.000000, Val Accuracy: 94.95%\n",
      "Epoch [27/50], Loss: 0.0060, LR: 0.000000, Val Accuracy: 95.40%\n",
      "Early stopping triggered at epoch 27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") # if torch.backends.cuda.is_available() else torch.device(\"cpu\")\n",
    "weights = models.ResNet50_Weights.DEFAULT\n",
    "model = models.resnet50(weights=weights).to(device)\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # unfrozed all layers\n",
    "\n",
    "# adjustment\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# replace the last layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 37).to(device)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset and DataLoader\n",
    "dataset_path = './dogvscat/multiclass_classification'\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.70 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "optimizer = Adam([\n",
    "    {'params': model.layer3.parameters(), 'lr': 0.0001},  \n",
    "    {'params': model.layer4.parameters(), 'lr': 0.00005},  \n",
    "    {'params': model.fc.parameters()}  # \n",
    "], lr=0.001)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "train_model_earlystop(model, criterion, optimizer, scheduler, num_epochs=50)\n",
    "# Load the best model and test it\n",
    "model.load_state_dict(torch.load('best_model.pth', weights_only=True))\n",
    "\n",
    "#train the full training set for best model\n",
    "#full_train_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
    "#full_train_loader = DataLoader(full_train_dataset, batch_size=32, shuffle=True)\n",
    "#retrain_model(model, criterion, optimizer, num_epochs=10)\n",
    "#test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "03fd9cb3-d66d-4965-a569-07cbfe9ca3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1009\n",
      "Epoch [2/10], Loss: 0.0880\n",
      "Epoch [3/10], Loss: 0.0857\n",
      "Epoch [4/10], Loss: 0.1197\n",
      "Epoch [5/10], Loss: 0.2051\n",
      "Epoch [6/10], Loss: 0.0053\n",
      "Epoch [7/10], Loss: 0.0056\n",
      "Epoch [8/10], Loss: 0.2822\n",
      "Epoch [9/10], Loss: 0.0064\n",
      "Epoch [10/10], Loss: 0.1795\n",
      "Test Accuracy: 95.04%\n"
     ]
    }
   ],
   "source": [
    "def retrain_model(model, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in full_train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "full_train_dataset = torch.utils.data.ConcatDataset([train_dataset, val_dataset])\n",
    "full_train_loader = DataLoader(full_train_dataset, batch_size=32, shuffle=True)\n",
    "retrain_model(model, criterion, optimizer, num_epochs=10)\n",
    "test_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
